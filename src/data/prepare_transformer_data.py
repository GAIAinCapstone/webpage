import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime

# ğŸ”§ config ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
from config.database import fetch_pollutant_data, get_database_connection

def load_all_weather_data(start_year=2018, end_year=2024):
    conn = get_database_connection(database_name='weatherCenter')
    all_weather = []
    try:
        for year in range(start_year, end_year + 1):
            table_name = f"processed_weather_{year}"
            query = f"SELECT * FROM {table_name} WHERE region = 'ë³´ë ¹'"
            df = pd.read_sql(query, conn)
            df['datetime'] = pd.to_datetime(df['datetime'])
            all_weather.append(df)
    finally:
        conn.close()
    return pd.concat(all_weather)

def load_all_pollutant_data():
    stations = ['ë³´ë ¹', 'ì‹ ë³´ë ¹', 'ì‹ ì„œì²œ']
    pollutants = ['nox', 'sox', 'tsp']
    all_data = []
    for station in stations:
        for pollutant in pollutants:
            table_name = f"tms_{station}_{pollutant}"
            df = fetch_pollutant_data(table_name, database_name='cleansys')
            if df.empty:
                continue
            df['ì •ë³´ì¼ì‹œ'] = pd.to_datetime(df['ì •ë³´ì¼ì‹œ'])
            df = df.rename(columns={'ì •ë³´ì¼ì‹œ': 'datetime', 'ê°’': f'{station}_{pollutant}'})
            all_data.append(df.set_index('datetime'))
    return pd.concat(all_data, axis=1).reset_index()

# ë°ì´í„° ë¡œë”©
weather_df = load_all_weather_data()
pollutant_df = load_all_pollutant_data()

# ì‹œê°„ ë‹¨ìœ„ë¡œ ì •ë ¬ ë° ë³‘í•©
weather_df['datetime_rounded'] = weather_df['datetime'].dt.floor('H')
pollutant_df['datetime_rounded'] = pollutant_df['datetime'].dt.floor('H')
merged_df = pd.merge(weather_df, pollutant_df, on='datetime_rounded', how='inner')

# íŠ¹ì„±ê³¼ íƒ€ê¹ƒ ì„ íƒ
feature_cols = ['speed', 'direction', 'temperature', 'humidity', 'sun_sa', 'total_cloud']
target_cols = [col for col in merged_df.columns if any(pol in col for pol in ['nox', 'sox', 'tsp'])]

features = merged_df[feature_cols].dropna()
targets = merged_df[target_cols].dropna()

min_len = min(len(features), len(targets))
features = features.iloc[:min_len]
targets = targets.iloc[:min_len]

os.makedirs("data/processed", exist_ok=True)
features.to_csv("data/processed/features.csv", index=False)
targets.to_csv("data/processed/targets.csv", index=False)

print("âœ… features.csv / targets.csv ìƒì„± ì™„ë£Œ!")
